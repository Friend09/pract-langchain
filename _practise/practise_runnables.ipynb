{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL & RUNNABLES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for langchain debugging\n",
    "from langchain_core.globals import set_debug\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASS DATA THROUGH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    passed=RunnablePassthrough(),  # 1\n",
    "    extra=RunnablePassthrough.assign(\n",
    "        mult=lambda x: x[\"num\"] * 3,  # 3\n",
    "    ),\n",
    "    modified=lambda x: x[\"num\"] + 1,  # 2\n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from operator import itemgetter\n",
    "\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"foo\") | RunnableLambda(length_function),  # 9\n",
    "        \"b\": {\n",
    "            \"text1\": itemgetter(\"foo\"),\n",
    "            \"text2\": itemgetter(\"bar\"),\n",
    "        }\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='9 + 54 = 63', response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-55ba4695-335f-4e15-9daa-e8e72554340a-0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"foo\": \"bartender\", \"bar\": \"garden\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACCEPTING RUNNABLE CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableConfig\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_or_fix(text: str, config: RunnableConfig):\n",
    "    fixing_chain = (\n",
    "        ChatPromptTemplate.from_template(\n",
    "            \"Fix the following text:\\n\\n```text\\n{input}\\n```\\nError: {error}\"\n",
    "            \" Don't narrate, just respond with the fixed data.\"\n",
    "        )\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            return json.loads(text)\n",
    "        except Exception as e:\n",
    "            text = fixing_chain.invoke(\n",
    "                {\n",
    "                    \"input\": text,\n",
    "                    \"error\": e,\n",
    "                },\n",
    "                config,\n",
    "            )\n",
    "    return \"Failed to parse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': 'bar'}\n",
      "Tokens Used: 62\n",
      "\tPrompt Tokens: 56\n",
      "\tCompletion Tokens: 6\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $9.6e-05\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    output = RunnableLambda(parse_or_fix).invoke(\n",
    "        \"{foo: bar}\", {\"tags\": [\"my-tag\"], \"callbacks\": [cb]}\n",
    "    )\n",
    "    print(output)\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DYNAMIC ROUTING BASED ON INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routing w/ Custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts\n",
    "promt_router = PromptTemplate.from_template(\n",
    "    \"\"\"Given the user question below, classify it as either being about `Bodybuilding`, `Jungian Psychology`, or `Other`.\n",
    "\n",
    "Do not respond with more than one word.\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\"\n",
    ")\n",
    "\n",
    "prompt_body_building = PromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in bodybuilding Always answer questions starting with \"As Dr. Mike Israetel from Rennaissance Periodization tol me\".\n",
    "\n",
    "    Respond to the following question:\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    ")\n",
    "\n",
    "prompt_jungian = PromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in Jungian Psychology and Theory. \\\n",
    "    Always answer questions starting with \"As Dr. C.G. Jung would say\". \\\n",
    "    Respond to the following question:\n",
    "\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    ")\n",
    "\n",
    "prompt_general = PromptTemplate.from_template(\n",
    "    \"\"\"Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chains\n",
    "chain_router = promt_router | llm | StrOutputParser()\n",
    "chain_body_building = prompt_body_building | llm\n",
    "chain_jungian = prompt_jungian | llm\n",
    "chain_general = prompt_general | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing_function(info):\n",
    "    if \"bodybuilding\" in info[\"topic\"].lower():\n",
    "        return chain_body_building\n",
    "    elif \"jungian psychology\" in info[\"topic\"].lower():\n",
    "        return chain_jungian\n",
    "    else:\n",
    "        return chain_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "chain_full = {\n",
    "    \"topic\": chain_router,\n",
    "    \"question\": lambda x: x[\"question\"],\n",
    "} | RunnableLambda(routing_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As Dr. C.G. Jung would say, alchemy and dreams are interconnected through the concept of transformation. Alchemy is a symbolic process of inner transformation, where base materials are transformed into gold, representing the individuation process. Dreams, on the other hand, are symbolic expressions of the unconscious mind, often containing images and symbols that reflect the individual's inner conflicts and desires. By exploring and interpreting dreams, one can uncover hidden aspects of the self and work towards psychological integration, similar to the alchemical process of transmutation.\", response_metadata={'token_usage': {'completion_tokens': 106, 'prompt_tokens': 58, 'total_tokens': 164}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2d54742b-f713-4c60-a998-35c412f074b2-0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_full.invoke({\"question\": \"what does alchemy have to do with dreams?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BINDING RUNTIME ARGUMENTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Write out 4 flashcard questions with their options based on the topic given below.. Use the format\\n Question:...\\nOPTIONS:...\\nSOLUTION:...\\n\\n\",\n",
    "        ),\n",
    "        (\"human\", \"{topic}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the purpose of using runnables in Langchain?\n",
      "OPTIONS: A) To execute code in a separate thread B) To handle exceptions C) To define custom data types D) To interact with databases\n",
      "SOLUTION: A) To execute code in a separate thread\n",
      "\n",
      "Question: How are runnables implemented in Langchain?\n",
      "OPTIONS: A) Using interfaces B) Using classes C) Using annotations D) Using enums\n",
      "SOLUTION: A) Using interfaces\n",
      "\n",
      "Question: Which method needs to be implemented when creating a runnable in Langchain?\n",
      "OPTIONS: A) run() B) start() C) execute() D) process()\n",
      "SOLUTION: A) run()\n",
      "\n",
      "Question: What is the benefit of using runnables in Langchain?\n",
      "OPTIONS: A) Improved performance B) Better memory management C) Easier debugging D) Enhanced security\n",
      "SOLUTION: A) Improved performance\n"
     ]
    }
   ],
   "source": [
    "chain = {\"topic\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke(\"langchain runnables\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the purpose of using runnables in Langchain?\n",
      "OPTIONS: A) To execute code concurrently B) To store data C) To create graphical user interfaces D) To handle exceptions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain_with_bind = (\n",
    "    {\"topic\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm.bind(stop=\"SOLUTION\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain_with_bind.invoke(\"langchain runnables\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPENAI FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = {\n",
    "    \"name\": \"return_questions\",\n",
    "    \"descriptions\": \"extracts questions from raw text\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"raw_text\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The raw text of flashcard questions\",\n",
    "            },\n",
    "            \"question\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"array of questions\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"question string\",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"equation\", \"solution\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Write out flashcard questions to the following topic then return the list of questions.\",\n",
    "        ),\n",
    "        (\"human\", \"{topic}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"raw_text\":\"1. What were the main causes of World War 2?\\\\n2. Which countries were part of the Axis Powers?\\\\n3. Which countries were part of the Allied Powers?\\\\n4. What event marked the beginning of World War 2?\\\\n5. Who was the leader of Nazi Germany during World War 2?\\\\n6. What was the significance of the Battle of Stalingrad?\\\\n7. What was the purpose of the D-Day invasion?\\\\n8. What were the major outcomes of the Yalta Conference?\\\\n9. How did World War 2 end in Europe?\\\\n10. What were the consequences of the atomic bombings of Hiroshima and Nagasaki?\\\\n11. What was the Holocaust?\\\\n12. How did World War 2 impact the global balance of power?\\\\n13. What was the Marshall Plan?\\\\n14. What were the Nuremberg Trials?\\\\n15. How did World War 2 lead to the creation of the United Nations?\"}', 'name': 'return_questions'}}, response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 91, 'total_tokens': 298}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_aa87380ac5', 'finish_reason': 'stop', 'logprobs': None}, id='run-7c031f28-15cf-4143-8915-cc3cc27a26a1-0')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_gpt4 = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind(\n",
    "    function_call={\"name\": \"return_questions\"}, functions=[function]\n",
    ")\n",
    "runnable = {\"topic\": RunnablePassthrough()} | prompt | llm_gpt4\n",
    "runnable.invoke(\"world war 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FALLBACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

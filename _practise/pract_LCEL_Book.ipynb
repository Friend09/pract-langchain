{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL\n",
    "\n",
    "https://python.langchain.com/docs/expression_language/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get api key\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7: OutputParsers and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Swiftphone\\n2. NexGen Mobile\\n3. OnTheGo Tech\\n4. PocketTech\\n5. Infinity Mobile\\n6. SmartLink\\n7. MobileMate\\n8. GoMobile\\n9. iConnect\\n10. Skyphone\\n11. TechTrail\\n12. MobileWave\\n13. NetEdge Mobile\\n14. ReachOut Tech\\n15. MobileFusion\\n16. NextMobile\\n17. UpLink Tech\\n18. MobileSphere\\n19. BoostTech\\n20. CellSpark']\n"
     ]
    }
   ],
   "source": [
    "# 7.1.1\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Suggest some names for my {subject} startup. \\n\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "print(\n",
    "    chain.invoke(\n",
    "        {\n",
    "            \"format_instructions\": format_instructions,\n",
    "            \"subject\": \"Mobile\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"Monument\": string  // The monument mentioned in the answer.\n",
      "\t\"city\": string  // the city in which this monument is present.\n",
      "\t\"architect\": string  // the architect of the monument.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# 7.1.2 Custom OutputParser\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "from operator import itemgetter\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(\n",
    "        name=\"Monument\",\n",
    "        description=\"The monument mentioned in the answer.\",\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"city\", description=\"the city in which this monument is present.\"\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"architect\",\n",
    "        description=\"the architect of the monument.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Monument': 'Taj Mahal', 'city': 'Agra', 'architect': 'Ustad Ahmad Lahauri'}\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "    answer the users question as best as possible. \\n\n",
    "    {format_instructions}\\n {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "print(\n",
    "    chain.invoke(\n",
    "        {\n",
    "            \"format_instructions\": format_instructions,\n",
    "            \"question\": \"Choose a random Indian state and pen down some cities\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.13"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
